# ============================================================
# VANCOUVER STORM DRAIN HAZARD DETECTOR - YOLOv11
# USING YOLO VERSION 11 (NOT v8!)
# ============================================================

print("üöÄ Starting YOLOv11 Training Pipeline\n")

# 1Ô∏è‚É£ INSTALL LATEST ULTRALYTICS (for YOLOv11 support)
print("üì¶ Installing latest Ultralytics (YOLOv11)...")
!pip install -q -U ultralytics roboflow pyyaml
print("‚úÖ Installed!\n")

import os, yaml, shutil, random
from roboflow import Roboflow
from ultralytics import YOLO
from google.colab import files
import torch

# Verify version (must be 8.3.0+ for YOLOv11)
from ultralytics import __version__
print(f"üìå Ultralytics version: {__version__}")
print("   (YOLOv11 requires 8.3.0+)\n")

# 2Ô∏è‚É£ CHECK GPU
print("üñ•Ô∏è  Checking GPU...")
if not torch.cuda.is_available():
    print("‚ùå GPU not found! Go to: Runtime ‚Üí Change runtime type ‚Üí T4 GPU")
    raise Exception("GPU required")
else:
    print(f"‚úÖ GPU: {torch.cuda.get_device_name(0)}")
    print(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\n")

# 3Ô∏è‚É£ DOWNLOAD DATASETS
print("=" * 60)
print("üì• DOWNLOADING DATASETS FROM ROBOFLOW")
print("=" * 60 + "\n")

rf = Roboflow(api_key="L44Fyu5glEfjyfNci0xy")

datasets = []

# Dataset 1: Traffic Cones
print("1Ô∏è‚É£  Downloading Traffic Cones (debris-6onrk)...")
try:
    project1 = rf.workspace("aimllab-tqjt3").project("debris-6onrk")
    version1 = project1.version(1)
    dataset1 = version1.download("yolov11")  # YOLOv11 format
    datasets.append(("cones", dataset1))
    train_count = len(os.listdir(f"{dataset1.location}/train/images"))
    print(f"   ‚úÖ Downloaded: {train_count} images\n")
except Exception as e:
    print(f"   ‚ùå Error: {e}\n")

# Dataset 2: Street Debris
print("2Ô∏è‚É£  Downloading Street Debris (litter-street-images)...")
try:
    project2 = rf.workspace("kabml-images").project("litter-street-images")
    version2 = project2.version(10)
    dataset2 = version2.download("yolov11")  # YOLOv11 format
    datasets.append(("debris", dataset2))
    train_count = len(os.listdir(f"{dataset2.location}/train/images"))
    print(f"   ‚úÖ Downloaded: {train_count} images\n")
except Exception as e:
    print(f"   ‚ùå Error: {e}\n")

# Dataset 3: Trash Cans
print("3Ô∏è‚É£  Downloading Trash Cans (trash-cans-segmentation)...")
try:
    project3 = rf.workspace("volobuevs-workspace").project("trash-cans-segmentation")
    version3 = project3.version(28)
    dataset3 = version3.download("yolov11")  # YOLOv11 format
    datasets.append(("trashcans", dataset3))
    train_count = len(os.listdir(f"{dataset3.location}/train/images"))
    print(f"   ‚úÖ Downloaded: {train_count} images\n")
except Exception as e:
    print(f"   ‚ùå Error: {e}\n")

if not datasets:
    raise Exception("‚ùå No datasets downloaded! Check API key and internet.")

print(f"‚úÖ Successfully downloaded {len(datasets)}/3 datasets\n")

# 4Ô∏è‚É£ CREATE COMBINED DATASET FOLDERS
print("üìÅ Creating combined dataset structure...")
for split in ["train", "valid", "test"]:
    os.makedirs(f"/content/combined/{split}/images", exist_ok=True)
    os.makedirs(f"/content/combined/{split}/labels", exist_ok=True)
print("‚úÖ Folders created\n")

# 5Ô∏è‚É£ MERGE DATASETS
print("=" * 60)
print("üîÑ MERGING DATASETS INTO MULTI-CLASS DATASET")
print("=" * 60 + "\n")

all_classes = {}
class_counter = 0

def merge_dataset(dataset_name, dataset, split, limit=1000):
    """Merge Roboflow dataset into combined folder with class remapping."""
    global class_counter, all_classes
    
    yaml_path = os.path.join(dataset.location, "data.yaml")
    if not os.path.exists(yaml_path):
        print(f"   ‚ö†Ô∏è {dataset_name}: No data.yaml found")
        return 0

    with open(yaml_path, "r") as f:
        data = yaml.safe_load(f)

    img_dir = os.path.join(dataset.location, split, "images")
    lbl_dir = os.path.join(dataset.location, split, "labels")
    
    if not os.path.exists(img_dir):
        return 0

    all_images = os.listdir(img_dir)
    random.shuffle(all_images)
    selected_images = all_images[:limit]

    count = 0
    
    for img_name in selected_images:
        lbl_name = os.path.splitext(img_name)[0] + ".txt"
        lbl_path = os.path.join(lbl_dir, lbl_name)
        
        if not os.path.exists(lbl_path):
            continue

        with open(lbl_path, "r") as f:
            lines = f.readlines()

        new_lines = []
        for line in lines:
            parts = line.strip().split()
            if len(parts) < 5:
                continue
            
            original_class_id = int(parts[0])
            if original_class_id >= len(data["names"]):
                continue
                
            original_class = data["names"][original_class_id]

            # === CLASS MAPPING RULES ===
            final_name = None
            
            if dataset_name == "cones":
                # debris-6onrk: extract cones and other debris
                if any(word in original_class.lower() for word in ["cone", "tube", "traffic"]):
                    final_name = "traffic_cone"
                else:
                    clean = original_class.lower().replace(' ', '_').replace('-', '_')
                    final_name = f"debris_{clean}"
                    
            elif dataset_name == "debris":
                # litter-street-images: all street debris
                clean = original_class.lower().replace(' ', '_').replace('-', '_')
                final_name = f"debris_{clean}"
                
            elif dataset_name == "trashcans":
                # trash-cans-segmentation: map to states
                lower_class = original_class.lower()
                if any(word in lower_class for word in ["empty", "open"]):
                    final_name = "trash_can_open"
                elif any(word in lower_class for word in ["full", "closed", "trash"]):
                    final_name = "trash_can_full"
                else:
                    final_name = "trash_can"

            if final_name is None:
                continue

            # Add to class dictionary
            if final_name not in all_classes:
                all_classes[final_name] = class_counter
                class_counter += 1

            # Write remapped label
            new_lines.append(f"{all_classes[final_name]} {' '.join(parts[1:])}\n")

        # Copy image and label if valid
        if new_lines:
            new_img_name = f"{dataset_name}_{img_name}"
            shutil.copy(
                os.path.join(img_dir, img_name),
                f"/content/combined/{split}/images/{new_img_name}"
            )
            
            new_lbl_name = f"{dataset_name}_{lbl_name}"
            with open(f"/content/combined/{split}/labels/{new_lbl_name}", "w") as f:
                f.writelines(new_lines)
            
            count += 1
            
    return count

# Merge all datasets
total_merged = 0
for name, ds in datasets:
    print(f"üì¶ Processing {name}...")
    dataset_total = 0
    for split in ["train", "valid", "test"]:
        count = merge_dataset(name, ds, split, limit=1000)
        dataset_total += count
        if count > 0:
            print(f"   {split}: {count} images")
    
    total_merged += dataset_total
    print(f"   ‚úÖ Total: {dataset_total} images\n")

print("=" * 60)
print(f"‚úÖ MERGE COMPLETE")
print(f"   Total images: {total_merged}")
print(f"   Total classes: {len(all_classes)}")
print("=" * 60 + "\n")

print("üìã Final Classes:")
for cls_name in sorted(all_classes.keys()):
    print(f"   - {cls_name}")
print()

# 6Ô∏è‚É£ CREATE DATA.YAML
print("üìù Creating data.yaml for YOLOv11...")

data_config = {
    "path": "/content/combined",
    "train": "train/images",
    "val": "valid/images",
    "test": "test/images",
    "nc": len(all_classes),
    "names": list(all_classes.keys())
}

with open("/content/combined/data.yaml", "w") as f:
    yaml.dump(data_config, f, default_flow_style=False)

print("‚úÖ data.yaml created\n")

print("Configuration:")
print("-" * 40)
with open("/content/combined/data.yaml", "r") as f:
    print(f.read())
print("-" * 40 + "\n")

# 7Ô∏è‚É£ TRAIN YOLOv11 MODEL
print("=" * 60)
print("üéØ TRAINING YOLOv11 MODEL")
print("=" * 60)
print("Model: YOLO11n (YOLOv11 Nano)")
print("Epochs: 30")
print("Image size: 640")
print("Batch size: 16")
print("‚è±Ô∏è  Estimated time: 15-25 minutes\n")

# Load YOLOv11n model (NOTE: yolo11n.pt NOT yolov8n.pt)
model = YOLO("yolo11n.pt")  # ‚Üê THIS IS YOLO VERSION 11

try:
    results = model.train(
        data="/content/combined/data.yaml",
        epochs=30,
        imgsz=640,
        batch=16,
        device=0,
        workers=8,
        cache=True,
        patience=10,
        name="vancouver_hazards_v11",
        verbose=True,
        plots=True
    )
    
    print("\n" + "=" * 60)
    print("‚úÖ YOLOv11 TRAINING COMPLETE!")
    print("=" * 60 + "\n")
    
except Exception as e:
    print(f"\n‚ùå Training error: {e}")
    import traceback
    traceback.print_exc()
    raise

# 8Ô∏è‚É£ VALIDATE MODEL
print("üìä Validating YOLOv11 model...\n")

try:
    metrics = model.val()
    
    print("=" * 60)
    print("üìà YOLOV11 VALIDATION METRICS")
    print("=" * 60)
    print(f"mAP50:     {metrics.box.map50:.3f}")
    print(f"mAP50-95:  {metrics.box.map:.3f}")
    print(f"Precision: {metrics.box.mp:.3f}")
    print(f"Recall:    {metrics.box.mr:.3f}")
    print("=" * 60 + "\n")
    
except Exception as e:
    print(f"‚ö†Ô∏è Validation error: {e}\n")

# 9Ô∏è‚É£ TEST INFERENCE
print("üß™ Testing YOLOv11 inference...\n")

try:
    valid_imgs = os.listdir("/content/combined/valid/images")
    if valid_imgs:
        test_img = f"/content/combined/valid/images/{random.choice(valid_imgs)}"
        print(f"Testing on: {os.path.basename(test_img)}\n")
        
        results = model(test_img, conf=0.25)
        results[0].save("yolov11_test_result.jpg")
        
        print("YOLOv11 Detections:")
        if len(results[0].boxes) == 0:
            print("  (No objects detected)")
        else:
            for box in results[0].boxes:
                cls = results[0].names[int(box.cls)]
                conf = float(box.conf)
                print(f"  ‚Ä¢ {cls}: {conf:.1%}")
        
        from IPython.display import Image, display
        print("\nüì∏ YOLOv11 Detection Result:")
        display(Image("yolov11_test_result.jpg", width=800))
except Exception as e:
    print(f"‚ö†Ô∏è Test error: {e}")

# üîü VIEW TRAINING PLOTS
print("\n" + "=" * 60)
print("üìä YOLOv11 TRAINING PLOTS")
print("=" * 60 + "\n")

from IPython.display import Image, display

results_dir = "/content/runs/detect/vancouver_hazards_v11"

plots = [
    ("results.png", "Training Metrics"),
    ("confusion_matrix.png", "Confusion Matrix"),
    ("F1_curve.png", "F1 Score"),
    ("PR_curve.png", "Precision-Recall")
]

for plot_file, title in plots:
    path = f"{results_dir}/{plot_file}"
    if os.path.exists(path):
        print(f"üìà {title}:")
        display(Image(path, width=800))
        print()

# 1Ô∏è‚É£1Ô∏è‚É£ DOWNLOAD YOLOv11 MODEL
print("=" * 60)
print("üíæ DOWNLOADING YOLOv11 TRAINED MODEL")
print("=" * 60 + "\n")

best_model = f"{results_dir}/weights/best.pt"
last_model = f"{results_dir}/weights/last.pt"

if os.path.exists(best_model):
    model_size = os.path.getsize(best_model) / 1e6
    print(f"üì• Downloading YOLOv11 best.pt ({model_size:.1f} MB)...")
    files.download(best_model)
    print("‚úÖ YOLOv11 best.pt downloaded!\n")
    
    if os.path.exists(last_model):
        print(f"üì• Downloading last.pt (backup)...")
        files.download(last_model)
        print("‚úÖ last.pt downloaded!\n")
else:
    print("‚ùå Model not found!")
    print(f"   Expected: {best_model}")

# 1Ô∏è‚É£2Ô∏è‚É£ SUMMARY
print("=" * 60)
print("üéâ YOLOv11 TRAINING COMPLETE!")
print("=" * 60)

print(f"\nüìä Statistics:")
print(f"   ‚Ä¢ Model: YOLOv11n (Version 11)")
print(f"   ‚Ä¢ Total images: {total_merged}")
print(f"   ‚Ä¢ Total classes: {len(all_classes)}")
print(f"   ‚Ä¢ Epochs trained: 30")

print(f"\nüìã Classes Detected ({len(all_classes)}):")
for cls_name in sorted(all_classes.keys()):
    print(f"   - {cls_name}")

print(f"\nüìÅ Outputs:")
print(f"   ‚Ä¢ Trained model: best.pt (YOLOv11)")
print(f"   ‚Ä¢ Results: {results_dir}")

print("\n‚úÖ Next Steps:")
print("   1. Upload best.pt to Hugging Face")
print("   2. Build frontend with YOLOv11 inference")
print("   3. Create demo video")

print("\n" + "=" * 60)
print("üöÄ YOLOv11 MODEL READY FOR DEPLOYMENT!")
print("=" * 60)
